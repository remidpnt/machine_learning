{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Remi\\Miniconda3\\envs\\fastai\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import html\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import collections\n",
    "import sys\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from pathlib import Path\n",
    "import nltk\n",
    "import tokenize\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikitext part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = r\"F:\\data\\text_classification\\preprocessed_wiki\\\\\"\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train  = []\n",
    "corpus_test   = []\n",
    "\n",
    "with open(\"F:\\data\\wikitext-103-v1\\wikitext-103\\wiki.train.tokens\", \"r\", encoding=\"utf8\") as f:\n",
    "    for i in f:\n",
    "        if i.find(\"=\")==-1 and len(i) > 15: #not a \\n line of a supersmall line \n",
    "            corpus_train.append(fixup(i).split(\" \"))         \n",
    "with open(\"F:\\data\\wikitext-103-v1\\wikitext-103\\wiki.test.tokens\", \"r\", encoding=\"utf8\") as f:\n",
    "    for i in f:\n",
    "        if i.find(\"=\")==-1 and len(i) > 15: #not a \\n line a supersmall line \n",
    "            corpus_test.append(fixup(i).split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846176\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2091"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(corpus_train))\n",
    "len((corpus_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 5580633),\n",
       " (',', 4969042),\n",
       " ('.', 3628837),\n",
       " ('of', 2723158),\n",
       " ('and', 2458189),\n",
       " ('to', 1972724),\n",
       " ('in', 1882952),\n",
       " ('a', 1675502),\n",
       " ('\"', 1337140),\n",
       " ('was', 1077209),\n",
       " ('The', 849891),\n",
       " ('', 848267),\n",
       " ('\\n', 848267),\n",
       " (\"'s\", 725981),\n",
       " ('on', 683132),\n",
       " ('that', 680199),\n",
       " ('as', 674890),\n",
       " ('for', 674140),\n",
       " ('with', 631106),\n",
       " ('by', 598734),\n",
       " (')', 571620),\n",
       " ('(', 571313),\n",
       " ('is', 511953),\n",
       " ('his', 437234),\n",
       " ('from', 431818),\n",
       " ('u_n', 420222),\n",
       " ('at', 415870),\n",
       " ('were', 355455),\n",
       " ('it', 326585),\n",
       " ('he', 318997),\n",
       " ('an', 306099),\n",
       " ('had', 293131),\n",
       " ('In', 279903),\n",
       " ('which', 275809),\n",
       " ('be', 234475),\n",
       " ('but', 203545),\n",
       " ('are', 203142),\n",
       " ('not', 194728),\n",
       " (';', 190579),\n",
       " ('their', 186708),\n",
       " ('first', 182485),\n",
       " ('also', 179984),\n",
       " ('her', 176682),\n",
       " ('–', 176595),\n",
       " (':', 175614),\n",
       " ('its', 174974),\n",
       " ('or', 166096),\n",
       " ('have', 163545),\n",
       " ('who', 155628),\n",
       " ('one', 152974),\n",
       " ('been', 152313),\n",
       " ('has', 150710),\n",
       " ('@,@', 149273),\n",
       " ('this', 145568),\n",
       " ('two', 144307),\n",
       " ('He', 141449),\n",
       " (\"'\", 137882),\n",
       " ('they', 135754),\n",
       " ('after', 129933),\n",
       " ('would', 126309),\n",
       " ('into', 123488),\n",
       " ('It', 119140),\n",
       " ('time', 115394),\n",
       " ('other', 113373),\n",
       " ('more', 109899),\n",
       " ('when', 102165),\n",
       " ('she', 100712),\n",
       " ('him', 100038),\n",
       " ('I', 98846),\n",
       " ('over', 97632),\n",
       " ('during', 96385),\n",
       " ('only', 92999),\n",
       " ('A', 92298),\n",
       " ('all', 92187),\n",
       " ('about', 90184),\n",
       " ('than', 89769),\n",
       " ('between', 88142),\n",
       " ('later', 87216),\n",
       " ('out', 86797),\n",
       " ('game', 85491),\n",
       " ('while', 83706),\n",
       " ('most', 83121),\n",
       " ('up', 81938),\n",
       " ('new', 81153),\n",
       " ('1', 80261),\n",
       " ('On', 80254),\n",
       " ('three', 77342),\n",
       " ('made', 76979),\n",
       " ('film', 76075),\n",
       " ('such', 75192),\n",
       " ('where', 74255),\n",
       " ('000', 74144),\n",
       " ('before', 73773),\n",
       " ('This', 71200),\n",
       " ('/', 70244),\n",
       " ('some', 70223),\n",
       " ('New', 69713),\n",
       " ('season', 69557),\n",
       " ('years', 69504),\n",
       " ('used', 69325),\n",
       " ('them', 68784),\n",
       " ('being', 67945),\n",
       " ('through', 66324),\n",
       " ('against', 66037),\n",
       " ('then', 64838),\n",
       " ('became', 63957),\n",
       " ('album', 63476),\n",
       " ('including', 63099),\n",
       " ('—', 62958),\n",
       " ('2', 62526),\n",
       " ('song', 62461),\n",
       " ('there', 62287),\n",
       " ('second', 61722),\n",
       " ('both', 61480),\n",
       " ('United', 61442),\n",
       " ('number', 61227),\n",
       " ('After', 61168),\n",
       " ('can', 60402),\n",
       " ('series', 60375),\n",
       " ('part', 59290),\n",
       " ('no', 57124),\n",
       " ('said', 56261),\n",
       " ('episode', 56197),\n",
       " ('many', 55924),\n",
       " ('year', 55858),\n",
       " ('several', 55225),\n",
       " ('team', 54591),\n",
       " ('could', 54026),\n",
       " ('under', 53944),\n",
       " ('well', 53673),\n",
       " ('did', 53649),\n",
       " ('began', 52720),\n",
       " ('so', 52274),\n",
       " ('known', 51323),\n",
       " ('work', 50930),\n",
       " ('3', 50799),\n",
       " ('until', 50369),\n",
       " ('four', 50175),\n",
       " ('American', 49864),\n",
       " ('early', 49859),\n",
       " ('As', 49766),\n",
       " ('released', 49260),\n",
       " ('called', 48707),\n",
       " ('million', 47152),\n",
       " ('these', 47042),\n",
       " ('$', 46851),\n",
       " ('British', 46506),\n",
       " ('She', 45777),\n",
       " ('found', 45150),\n",
       " ('September', 44893),\n",
       " ('people', 44390),\n",
       " ('because', 44375),\n",
       " ('end', 44174),\n",
       " ('States', 44096),\n",
       " ('same', 44080),\n",
       " ('At', 44041),\n",
       " ('music', 43815),\n",
       " ('around', 43193),\n",
       " ('took', 43074),\n",
       " ('may', 42998),\n",
       " ('10', 42756),\n",
       " ('following', 42331),\n",
       " ('However', 42101),\n",
       " ('day', 41906),\n",
       " ('any', 41857),\n",
       " ('use', 41731),\n",
       " ('August', 41538),\n",
       " ('along', 41296),\n",
       " ('received', 41248),\n",
       " ('World', 41234),\n",
       " ('October', 41127),\n",
       " ('John', 40803),\n",
       " ('each', 40537),\n",
       " ('km', 40364),\n",
       " ('4', 40282),\n",
       " ('May', 40146),\n",
       " ('They', 40016),\n",
       " ('area', 39732),\n",
       " (']', 39495),\n",
       " ('[', 39419),\n",
       " ('back', 39351),\n",
       " ('June', 38887),\n",
       " ('state', 38475),\n",
       " ('%', 38426),\n",
       " ('July', 38189),\n",
       " ('city', 38134),\n",
       " ('November', 37934),\n",
       " ('since', 37764),\n",
       " ('like', 37717),\n",
       " ('show', 37570),\n",
       " ('April', 37172),\n",
       " ('War', 36686),\n",
       " ('March', 36546),\n",
       " ('will', 36195),\n",
       " ('5', 36132),\n",
       " ('During', 35714),\n",
       " ('York', 35487),\n",
       " ('US', 35118),\n",
       " ('due', 35074),\n",
       " ('December', 35050),\n",
       " ('set', 34908),\n",
       " ('played', 34906),\n",
       " ('another', 34871),\n",
       " ('included', 34818),\n",
       " ('five', 34755),\n",
       " ('if', 34726),\n",
       " ('off', 34672),\n",
       " ('January', 34569),\n",
       " ('much', 34549),\n",
       " ('what', 34475),\n",
       " ('large', 34305),\n",
       " ('single', 34053),\n",
       " ('left', 33971),\n",
       " ('When', 33948),\n",
       " ('group', 33771),\n",
       " ('system', 33623),\n",
       " ('character', 33622),\n",
       " ('name', 33579),\n",
       " ('wrote', 33550),\n",
       " ('won', 33517),\n",
       " ('down', 33383),\n",
       " ('century', 33197),\n",
       " ('place', 32972),\n",
       " ('long', 32943),\n",
       " ('North', 32896),\n",
       " ('own', 32740),\n",
       " ('described', 32591),\n",
       " ('government', 32492),\n",
       " ('...', 32427),\n",
       " ('final', 32386),\n",
       " ('just', 32180),\n",
       " ('named', 32078),\n",
       " ('home', 31961),\n",
       " ('family', 31799),\n",
       " ('led', 31772),\n",
       " ('band', 31365),\n",
       " ('20', 31299),\n",
       " ('South', 31203),\n",
       " ('very', 30983),\n",
       " ('those', 30948),\n",
       " ('now', 30926),\n",
       " ('games', 30885),\n",
       " ('war', 30851),\n",
       " ('line', 30838),\n",
       " ('third', 30803),\n",
       " ('high', 30752),\n",
       " (\"'t\", 30607),\n",
       " ('February', 30483),\n",
       " ('m', 30482),\n",
       " ('next', 30310),\n",
       " ('ship', 30296),\n",
       " ('life', 30267),\n",
       " ('near', 30231),\n",
       " ('still', 30114),\n",
       " ('make', 30094),\n",
       " ('By', 30033),\n",
       " ('main', 30022),\n",
       " ('species', 29944),\n",
       " ('12', 29693),\n",
       " ('within', 29647),\n",
       " ('original', 29524),\n",
       " ('last', 29513),\n",
       " ('record', 29512),\n",
       " ('men', 29486),\n",
       " ('although', 29430),\n",
       " ('6', 29367),\n",
       " ('world', 29347),\n",
       " ('15', 29139),\n",
       " ('His', 29053),\n",
       " ('held', 28928),\n",
       " ('major', 28914),\n",
       " ('30', 28852),\n",
       " ('again', 28833),\n",
       " ('small', 28764),\n",
       " ('death', 28603),\n",
       " ('National', 28575),\n",
       " ('days', 28430),\n",
       " ('There', 28385),\n",
       " ('2010', 28258),\n",
       " ('built', 28239),\n",
       " ('however', 28119),\n",
       " ('French', 27950),\n",
       " ('late', 27809),\n",
       " ('video', 27603),\n",
       " ('release', 27541),\n",
       " ('German', 27520),\n",
       " ('you', 27502),\n",
       " ('continued', 27480),\n",
       " ('six', 27336),\n",
       " ('often', 27332),\n",
       " ('role', 27292),\n",
       " ('based', 27226),\n",
       " ('members', 27176),\n",
       " ('came', 27042),\n",
       " ('match', 27041),\n",
       " ('even', 26983),\n",
       " ('2008', 26949),\n",
       " ('2009', 26947),\n",
       " ('north', 26831),\n",
       " ('do', 26682),\n",
       " ('2011', 26567),\n",
       " ('England', 26384),\n",
       " ('&', 26380),\n",
       " ('100', 26362),\n",
       " ('considered', 26282),\n",
       " ('play', 26229),\n",
       " ('former', 26196),\n",
       " ('public', 26111),\n",
       " ('way', 26108),\n",
       " ('further', 26064),\n",
       " ('having', 25834),\n",
       " ('best', 25783),\n",
       " ('7', 25618),\n",
       " ('moved', 25606),\n",
       " ('11', 25568),\n",
       " ('2007', 25406),\n",
       " ('without', 25379),\n",
       " ('Although', 25376),\n",
       " ('few', 25340),\n",
       " ('local', 25332),\n",
       " ('become', 25234),\n",
       " ('school', 25178),\n",
       " ('storm', 25069),\n",
       " ('City', 25064),\n",
       " ('One', 25050),\n",
       " ('form', 25043),\n",
       " ('support', 24996),\n",
       " ('different', 24903),\n",
       " ('version', 24837),\n",
       " ('among', 24735),\n",
       " ('take', 24706),\n",
       " ('8', 24606),\n",
       " ('book', 24510),\n",
       " ('2012', 24505),\n",
       " ('de', 24455),\n",
       " ('story', 24430),\n",
       " ('power', 24396),\n",
       " ('London', 24354),\n",
       " ('period', 24330),\n",
       " ('though', 24301),\n",
       " ('For', 24287),\n",
       " ('side', 24208),\n",
       " ('water', 24063),\n",
       " ('production', 23923),\n",
       " ('we', 23910),\n",
       " ('given', 23823),\n",
       " ('south', 23816),\n",
       " ('gave', 23758),\n",
       " ('player', 23630),\n",
       " ('English', 23617),\n",
       " ('While', 23589),\n",
       " ('returned', 23531),\n",
       " ('top', 23517),\n",
       " ('II', 23479),\n",
       " ('University', 23473),\n",
       " ('King', 23457),\n",
       " ('written', 23431),\n",
       " ('went', 23258),\n",
       " ('position', 23127),\n",
       " ('company', 23073),\n",
       " ('U.S.', 23065),\n",
       " ('published', 22904),\n",
       " ('stated', 22804),\n",
       " ('18', 22773),\n",
       " ('lost', 22699),\n",
       " ('River', 22666),\n",
       " ('include', 22547),\n",
       " ('16', 22488),\n",
       " ('9', 22433),\n",
       " ('14', 22359),\n",
       " ('13', 22259),\n",
       " ('West', 22223),\n",
       " ('order', 22216),\n",
       " ('lead', 22175),\n",
       " ('ships', 22167),\n",
       " ('similar', 22139),\n",
       " ('2006', 22077),\n",
       " ('forces', 22054),\n",
       " ('According', 22054),\n",
       " ('town', 22025),\n",
       " ('using', 22017),\n",
       " ('attack', 22009),\n",
       " ('25', 21955),\n",
       " ('never', 21927),\n",
       " ('produced', 21896),\n",
       " ('building', 21893),\n",
       " ('These', 21830),\n",
       " ('himself', 21750),\n",
       " ('recorded', 21749),\n",
       " ('point', 21490),\n",
       " ('songs', 21366),\n",
       " ('Australia', 21332),\n",
       " ('total', 21304),\n",
       " ('country', 21279),\n",
       " ('military', 21231),\n",
       " ('history', 21046),\n",
       " ('2013', 21028),\n",
       " ('making', 20872),\n",
       " ('service', 20862),\n",
       " ('times', 20847),\n",
       " ('remained', 20778),\n",
       " ('ft', 20737),\n",
       " ('died', 20572),\n",
       " ('James', 20555),\n",
       " ('result', 20527),\n",
       " ('months', 20524),\n",
       " ('father', 20516),\n",
       " ('per', 20506),\n",
       " ('how', 20459),\n",
       " ('Army', 20438),\n",
       " ('career', 20433),\n",
       " ('characters', 20341),\n",
       " ('club', 20312),\n",
       " ('previous', 20279),\n",
       " ('performance', 20266),\n",
       " ('William', 20218),\n",
       " ('less', 20185),\n",
       " ('children', 20146),\n",
       " ('title', 20121),\n",
       " ('control', 20065),\n",
       " ('across', 20027),\n",
       " ('State', 20018),\n",
       " ('developed', 19916),\n",
       " ('development', 19891),\n",
       " ('reported', 19865),\n",
       " ('away', 19865),\n",
       " ('east', 19761),\n",
       " ('felt', 19730),\n",
       " ('track', 19682),\n",
       " ('noted', 19643),\n",
       " ('reached', 19619),\n",
       " ('aircraft', 19609),\n",
       " ('announced', 19601),\n",
       " ('Division', 19522),\n",
       " ('League', 19503),\n",
       " ('areas', 19362),\n",
       " ('sent', 19263),\n",
       " ('created', 19181),\n",
       " ('17', 19178),\n",
       " ('short', 19112),\n",
       " ('return', 19108),\n",
       " ('’', 19070),\n",
       " ('followed', 19048),\n",
       " ('seen', 19047),\n",
       " ('good', 19035),\n",
       " ('America', 19028),\n",
       " ('land', 19025),\n",
       " ('County', 19021),\n",
       " ('should', 18978),\n",
       " ('television', 18917),\n",
       " ('too', 18869),\n",
       " ('served', 18866),\n",
       " ('performed', 18860),\n",
       " ('force', 18838),\n",
       " ('s', 18835),\n",
       " ('players', 18754),\n",
       " ('win', 18705),\n",
       " ('With', 18688),\n",
       " ('right', 18671),\n",
       " ('2005', 18664),\n",
       " ('political', 18646),\n",
       " ('Street', 18630),\n",
       " ('house', 18594),\n",
       " ('General', 18588),\n",
       " ('George', 18571),\n",
       " ('week', 18570),\n",
       " ('killed', 18496),\n",
       " ('various', 18430),\n",
       " ('fire', 18407),\n",
       " ('Japanese', 18387),\n",
       " ('throughout', 18385),\n",
       " ('24', 18381),\n",
       " ('taken', 18339),\n",
       " ('Park', 18257),\n",
       " ('run', 18224),\n",
       " ('tropical', 18192),\n",
       " ('2014', 18170),\n",
       " ('able', 18163),\n",
       " ('man', 18136),\n",
       " ('head', 18106),\n",
       " ('design', 18104),\n",
       " ('west', 18068),\n",
       " ('son', 18022),\n",
       " ('little', 18021),\n",
       " ('great', 17949),\n",
       " ('appeared', 17935),\n",
       " ('miles', 17877),\n",
       " ('half', 17765),\n",
       " ('mm', 17717),\n",
       " ('points', 17653),\n",
       " ('!', 17646),\n",
       " ('success', 17622),\n",
       " ('route', 17614),\n",
       " ('Road', 17607),\n",
       " ('caused', 17600),\n",
       " ('started', 17589),\n",
       " ('thought', 17555),\n",
       " ('addition', 17521),\n",
       " ('women', 17500),\n",
       " ('eventually', 17492),\n",
       " ('writing', 17492),\n",
       " ('Australian', 17456),\n",
       " ('21', 17445),\n",
       " ('established', 17403),\n",
       " ('decided', 17379),\n",
       " ('features', 17346),\n",
       " ('road', 17232),\n",
       " ('feet', 17177),\n",
       " ('battle', 17150),\n",
       " ('added', 17131),\n",
       " ('member', 17121),\n",
       " ('together', 17116),\n",
       " ('located', 17063),\n",
       " ('22', 17035),\n",
       " ('instead', 17001),\n",
       " ('once', 16975),\n",
       " ('sold', 16904),\n",
       " ('national', 16898),\n",
       " ('formed', 16887),\n",
       " ('David', 16829),\n",
       " ('19', 16736),\n",
       " ('completed', 16710),\n",
       " ('common', 16620),\n",
       " ('old', 16595),\n",
       " ('age', 16592),\n",
       " ('body', 16561),\n",
       " ('eight', 16495),\n",
       " ('population', 16445),\n",
       " ('rather', 16414),\n",
       " ('race', 16380),\n",
       " ('others', 16374),\n",
       " ('important', 16372),\n",
       " ('All', 16362),\n",
       " ('general', 16294),\n",
       " ('Royal', 16264),\n",
       " ('50', 16233),\n",
       " ('saw', 16223),\n",
       " ('seven', 16222),\n",
       " ('House', 16202),\n",
       " ('opened', 16136),\n",
       " ('range', 16101),\n",
       " ('23', 16078),\n",
       " ('worked', 16062),\n",
       " ('station', 16037),\n",
       " ('2004', 16029),\n",
       " ('Michael', 16007),\n",
       " ('campaign', 15972),\n",
       " ('behind', 15967),\n",
       " ('guns', 15932),\n",
       " ('get', 15894),\n",
       " ('weeks', 15860),\n",
       " ('h', 15848),\n",
       " ('site', 15837),\n",
       " ('East', 15831),\n",
       " ('originally', 15822),\n",
       " ('France', 15702),\n",
       " ('damage', 15698),\n",
       " ('almost', 15669),\n",
       " ('works', 15666),\n",
       " ('tour', 15596),\n",
       " ('upon', 15593),\n",
       " ('2015', 15590),\n",
       " ('every', 15561),\n",
       " ('style', 15556),\n",
       " ('provided', 15554),\n",
       " ('stage', 15521),\n",
       " ('popular', 15467),\n",
       " ('leading', 15463),\n",
       " ('Henry', 15463),\n",
       " ('To', 15462),\n",
       " ('scored', 15453),\n",
       " ('construction', 15435),\n",
       " ('brought', 15413),\n",
       " ('young', 15410),\n",
       " ('Best', 15399),\n",
       " ('air', 15350),\n",
       " ('strong', 15346),\n",
       " ('scene', 15335),\n",
       " ('event', 15302),\n",
       " ('featured', 15299),\n",
       " ('allowed', 15286),\n",
       " ('Some', 15286),\n",
       " ('You', 15274),\n",
       " ('night', 15249),\n",
       " ('wanted', 15226),\n",
       " ('towards', 15219),\n",
       " ('least', 15202),\n",
       " ('live', 15200),\n",
       " ('playing', 15195),\n",
       " ('mi', 15193),\n",
       " ('heavy', 15190),\n",
       " ('see', 15188),\n",
       " ('my', 15178),\n",
       " ('case', 15176),\n",
       " ('action', 15098),\n",
       " ('either', 15094),\n",
       " ('close', 15085),\n",
       " ('ten', 15083),\n",
       " ('help', 15081),\n",
       " ('party', 15042),\n",
       " ('critics', 15039),\n",
       " ('does', 15026),\n",
       " ('average', 14986),\n",
       " ('put', 14978),\n",
       " ('Robert', 14976),\n",
       " ('troops', 14970),\n",
       " ('region', 14960),\n",
       " ('runs', 14949),\n",
       " ('example', 14885),\n",
       " ('An', 14867),\n",
       " ('placed', 14839),\n",
       " ('Despite', 14824),\n",
       " ('Washington', 14823),\n",
       " ('army', 14775),\n",
       " ('light', 14756),\n",
       " ('generally', 14701),\n",
       " ('working', 14696),\n",
       " ('joined', 14663),\n",
       " ('front', 14652),\n",
       " ('27', 14589),\n",
       " ('Air', 14588),\n",
       " ('wife', 14583),\n",
       " ('40', 14581),\n",
       " ('Europe', 14561),\n",
       " ('believed', 14546),\n",
       " ('School', 14528),\n",
       " ('Following', 14483),\n",
       " ('fourth', 14474),\n",
       " ('field', 14471),\n",
       " ('28', 14403),\n",
       " ('white', 14383),\n",
       " ('mph', 14383),\n",
       " ('replaced', 14365),\n",
       " ('born', 14360),\n",
       " ('2003', 14348),\n",
       " ('26', 14333),\n",
       " ('events', 14309),\n",
       " ('victory', 14287),\n",
       " ('present', 14248),\n",
       " ('level', 14232),\n",
       " ('hit', 14228),\n",
       " ('500', 14225),\n",
       " ('ever', 14153),\n",
       " ('involved', 14140),\n",
       " ('Japan', 14113),\n",
       " ('ground', 14105),\n",
       " ('project', 14101),\n",
       " ('office', 14093),\n",
       " ('hours', 14075),\n",
       " ('finished', 14052),\n",
       " ('designed', 14013),\n",
       " ('saying', 13983),\n",
       " ('successful', 13949),\n",
       " ('low', 13934),\n",
       " ('go', 13916),\n",
       " ('mother', 13913),\n",
       " ('full', 13911),\n",
       " ('soon', 13903),\n",
       " ('rest', 13889),\n",
       " ('200', 13889),\n",
       " ('island', 13889),\n",
       " ('black', 13852),\n",
       " ('start', 13811),\n",
       " ('law', 13792),\n",
       " ('President', 13790),\n",
       " ('possible', 13772),\n",
       " ('minutes', 13710),\n",
       " ('initially', 13704),\n",
       " ('earlier', 13695),\n",
       " ('particularly', 13682),\n",
       " ('available', 13667),\n",
       " ('modern', 13614),\n",
       " ('opening', 13586),\n",
       " ('forced', 13585),\n",
       " ('significant', 13565),\n",
       " ('highway', 13522),\n",
       " ('met', 13494),\n",
       " ('Two', 13453),\n",
       " ('European', 13436),\n",
       " ('training', 13424),\n",
       " ('Cup', 13420),\n",
       " ('me', 13391),\n",
       " ('°', 13376),\n",
       " ('process', 13347),\n",
       " ('Battle', 13339),\n",
       " ('Navy', 13334),\n",
       " ('special', 13329),\n",
       " ('crew', 13287),\n",
       " ('open', 13265),\n",
       " ('praised', 13263),\n",
       " ('increased', 13254),\n",
       " ('turned', 13254),\n",
       " ('passed', 13253),\n",
       " ('2001', 13252),\n",
       " ('shot', 13243),\n",
       " ('2000', 13241),\n",
       " ('southern', 13226),\n",
       " ('From', 13219),\n",
       " ('ended', 13197),\n",
       " ('Charles', 13165),\n",
       " ('studio', 13160),\n",
       " ('Kingdom', 13102),\n",
       " ('command', 13089),\n",
       " ('director', 13036),\n",
       " ('largest', 13031),\n",
       " ('appearance', 12988),\n",
       " ('Thomas', 12981),\n",
       " ('units', 12965),\n",
       " ('official', 12965),\n",
       " ('far', 12953),\n",
       " ('No.', 12917),\n",
       " ('San', 12876),\n",
       " ('change', 12873),\n",
       " ('relationship', 12812),\n",
       " ('First', 12790),\n",
       " ('ordered', 12779),\n",
       " ('2002', 12768),\n",
       " ('Canada', 12760),\n",
       " ('taking', 12710),\n",
       " ('northern', 12709),\n",
       " ('hurricane', 12673),\n",
       " ('Other', 12657),\n",
       " ('move', 12651),\n",
       " ('winds', 12622),\n",
       " ('enough', 12588),\n",
       " ('spent', 12554),\n",
       " ('rock', 12533),\n",
       " ('California', 12517),\n",
       " ('love', 12511),\n",
       " ('chart', 12495),\n",
       " ('signed', 12494),\n",
       " ('must', 12469),\n",
       " ('goal', 12464),\n",
       " ('outside', 12438),\n",
       " ('told', 12437),\n",
       " ('Paul', 12437),\n",
       " ('list', 12434),\n",
       " ('attempt', 12407),\n",
       " ('previously', 12370),\n",
       " ('positive', 12356),\n",
       " ('films', 12352),\n",
       " ('29', 12350),\n",
       " ('find', 12346),\n",
       " ('failed', 12339),\n",
       " ('church', 12304),\n",
       " ('required', 12250),\n",
       " ('better', 12246),\n",
       " ('going', 12242),\n",
       " ('Company', 12234),\n",
       " ('Music', 12211),\n",
       " ('come', 12184),\n",
       " ('sound', 12165),\n",
       " ('elements', 12158),\n",
       " ('parts', 12150),\n",
       " ('itself', 12148),\n",
       " ('court', 12128),\n",
       " ('despite', 12108),\n",
       " ('Germany', 12083),\n",
       " ('Great', 12076),\n",
       " ('reviews', 12066),\n",
       " ('entire', 12052),\n",
       " ('Union', 12033),\n",
       " ('according', 12032),\n",
       " ('£', 12015),\n",
       " ('cast', 12011),\n",
       " ('class', 12009),\n",
       " ('central', 12005),\n",
       " ('Award', 12003),\n",
       " ('International', 11973),\n",
       " ('beginning', 11971),\n",
       " ('above', 11965),\n",
       " ('recording', 11909),\n",
       " ('India', 11907),\n",
       " ('whose', 11886),\n",
       " ('?', 11873),\n",
       " ('claimed', 11857),\n",
       " ('asked', 11822),\n",
       " ('Island', 11816),\n",
       " ('interest', 11802),\n",
       " ('directed', 11792),\n",
       " ('groups', 11790),\n",
       " ('Court', 11782),\n",
       " ('additional', 11733),\n",
       " ('human', 11715),\n",
       " ('whom', 11710),\n",
       " ('give', 11685),\n",
       " ('Route', 11677),\n",
       " ('We', 11641),\n",
       " ('states', 11635),\n",
       " ('lines', 11626),\n",
       " ('review', 11621),\n",
       " ('free', 11621),\n",
       " ('quickly', 11613),\n",
       " ('future', 11607),\n",
       " ('idea', 11599),\n",
       " ('base', 11596),\n",
       " ('Hall', 11584),\n",
       " ('UK', 11545),\n",
       " ('evidence', 11536),\n",
       " ('introduced', 11521),\n",
       " ('Smith', 11468),\n",
       " ('international', 11452),\n",
       " ('already', 11444),\n",
       " ('That', 11441),\n",
       " ('Peter', 11432),\n",
       " ('arrived', 11426),\n",
       " ('College', 11409),\n",
       " ('usually', 11405),\n",
       " ('White', 11383),\n",
       " ('month', 11367),\n",
       " ('section', 11359),\n",
       " ('31', 11351),\n",
       " ('cover', 11335),\n",
       " ('0', 11335),\n",
       " ('coast', 11324),\n",
       " ('Times', 11324),\n",
       " ('novel', 11309),\n",
       " ('Richard', 11292),\n",
       " ('Indian', 11282),\n",
       " ('sometimes', 11270),\n",
       " ('Force', 11267),\n",
       " ('especially', 11258),\n",
       " ('NY', 11255),\n",
       " ('Church', 11247),\n",
       " ('Black', 11236),\n",
       " ('Britain', 11233),\n",
       " ('football', 11226),\n",
       " ('art', 11212),\n",
       " ('study', 11209),\n",
       " ('magazine', 11200),\n",
       " ('loss', 11193),\n",
       " ('carried', 11135),\n",
       " ('estimated', 11132),\n",
       " ('St.', 11130),\n",
       " ('league', 11130),\n",
       " ('lower', 11129),\n",
       " ('Most', 11118),\n",
       " ('program', 11117),\n",
       " ('debut', 11096),\n",
       " ('remaining', 11090),\n",
       " ('defeated', 11083),\n",
       " ('score', 11061),\n",
       " ('shows', 11044),\n",
       " ('social', 11034),\n",
       " ('becoming', 11009),\n",
       " ('money', 10990),\n",
       " ('Western', 10975),\n",
       " ('Championship', 10965),\n",
       " ('community', 10948),\n",
       " ('female', 10938),\n",
       " ('suggested', 10930),\n",
       " ('complete', 10920),\n",
       " ('police', 10913),\n",
       " ('bridge', 10897),\n",
       " ('issue', 10894),\n",
       " ('plan', 10876),\n",
       " ('might', 10873),\n",
       " ('king', 10864),\n",
       " ('decision', 10861),\n",
       " ('musical', 10860),\n",
       " ('teams', 10835),\n",
       " ('larger', 10831),\n",
       " ('students', 10820),\n",
       " ('center', 10819),\n",
       " ('latter', 10801),\n",
       " ('Virginia', 10784),\n",
       " ('percent', 10777),\n",
       " ('1999', 10752),\n",
       " ('business', 10738),\n",
       " ('sea', 10721),\n",
       " ('surface', 10715),\n",
       " ('episodes', 10712),\n",
       " ('nine', 10710),\n",
       " ('destroyed', 10695),\n",
       " ('western', 10678),\n",
       " ('leaving', 10653),\n",
       " ('turn', 10588),\n",
       " ('appointed', 10580),\n",
       " ('provide', 10573),\n",
       " ('entered', 10566),\n",
       " ('material', 10545),\n",
       " ('Los', 10543),\n",
       " ('If', 10541),\n",
       " ('highest', 10525),\n",
       " ('summer', 10499),\n",
       " ('changes', 10498),\n",
       " ('proposed', 10468),\n",
       " ('fleet', 10457),\n",
       " ('overall', 10445),\n",
       " ('Her', 10440),\n",
       " ('lack', 10417),\n",
       " ('brother', 10413),\n",
       " ('intended', 10403),\n",
       " ('eastern', 10383),\n",
       " ('agreed', 10372),\n",
       " ('rights', 10333),\n",
       " ('fact', 10328),\n",
       " ('Association', 10320),\n",
       " ('past', 10320),\n",
       " ('nearly', 10309),\n",
       " ('president', 10303),\n",
       " ('helped', 10299),\n",
       " ('Party', 10275),\n",
       " ('High', 10268),\n",
       " ('married', 10264),\n",
       " ('Many', 10253),\n",
       " ('awarded', 10252),\n",
       " ('scenes', 10252),\n",
       " ('limited', 10243),\n",
       " ('influence', 10227),\n",
       " ('date', 10225),\n",
       " ('daughter', 10211),\n",
       " ('supported', 10196),\n",
       " ('effects', 10182),\n",
       " ('river', 10169),\n",
       " ('response', 10164),\n",
       " ('pressure', 10156),\n",
       " ('writer', 10116),\n",
       " ('structure', 10111),\n",
       " ('create', 10105),\n",
       " ('movement', 10103),\n",
       " ('contract', 10099),\n",
       " ('B', 10096),\n",
       " ('food', 10096),\n",
       " ('appear', 10070),\n",
       " ('Edward', 10064),\n",
       " ('Awards', 10062),\n",
       " ('Jackson', 10038),\n",
       " ('captured', 10038),\n",
       " ('compared', 10023),\n",
       " ('Spanish', 10001),\n",
       " ('changed', 9998),\n",
       " ('election', 9995),\n",
       " ('size', 9989),\n",
       " ('approximately', 9986),\n",
       " ('Chicago', 9978),\n",
       " ('1998', 9977),\n",
       " ('planned', 9970),\n",
       " ('themselves', 9965),\n",
       " ('Chinese', 9920),\n",
       " ('speed', 9913),\n",
       " ('mostly', 9910),\n",
       " ('car', 9910),\n",
       " ('Red', 9907),\n",
       " ('fans', 9902),\n",
       " ('experience', 9899),\n",
       " ('done', 9892),\n",
       " ('Council', 9867),\n",
       " ('longer', 9864),\n",
       " ('course', 9859),\n",
       " ('Hill', 9858),\n",
       " ('personal', 9849),\n",
       " ('staff', 9842),\n",
       " ('Billboard', 9842),\n",
       " ('cut', 9842),\n",
       " ('room', 9839),\n",
       " ('thus', 9839),\n",
       " ('remains', 9823),\n",
       " ('tracks', 9815),\n",
       " ('Johnson', 9806),\n",
       " ('Act', 9804),\n",
       " ('our', 9774),\n",
       " ('living', 9772),\n",
       " ('whether', 9765),\n",
       " ('probably', 9758),\n",
       " ('Club', 9741),\n",
       " ('round', 9741),\n",
       " ('Soviet', 9737),\n",
       " ('running', 9736),\n",
       " ('soldiers', 9717),\n",
       " ('research', 9717),\n",
       " ('commercial', 9707),\n",
       " ('copies', 9695),\n",
       " ('length', 9686),\n",
       " ('cost', 9669),\n",
       " ('person', 9641),\n",
       " ('really', 9640),\n",
       " ('suffered', 9634),\n",
       " ('Since', 9621),\n",
       " ('difficult', 9615),\n",
       " ('buildings', 9601),\n",
       " ('O', 9596),\n",
       " ('Grand', 9588),\n",
       " ('operations', 9587),\n",
       " ('extended', 9587),\n",
       " ('immediately', 9583),\n",
       " ('real', 9579),\n",
       " ('includes', 9576),\n",
       " ('countries', 9573),\n",
       " ('star', 9544),\n",
       " ('current', 9525),\n",
       " ('higher', 9524),\n",
       " ('issued', 9515),\n",
       " ('division', 9513),\n",
       " ('media', 9509),\n",
       " ('stars', 9499),\n",
       " ('Later', 9496),\n",
       " ('likely', 9496),\n",
       " ('radio', 9487),\n",
       " ('leader', 9464),\n",
       " ...]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = 30000\n",
    "freq       = Counter(p for o in corpus_train+corpus_val for p in o)\n",
    "freq.most_common(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_list = [ s for s,i in freq.most_common(vocab_size) if i>2 ]\n",
    "string_list.insert(0,\"_unk_\")\n",
    "string_list.insert(1,\"_pad_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30002"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(string_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos        = {st:index for st, index in enumerate(string_list)}\n",
    "stoi        = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(string_list)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hundred'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len_train = sum([len(a) for a in corpus_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokken_corpus_train = []\n",
    "tokken_corpus_val   = []\n",
    "\n",
    "for i in range(len(corpus_train)):\n",
    "    for a in corpus_train[i]:\n",
    "        tokken_corpus_train.append(stoi[a])\n",
    "        \n",
    "for i in range(len(corpus_val)):\n",
    "    for a in corpus_val[i]:\n",
    "        tokken_corpus_val.append(stoi[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokken_corpus_train) == total_len_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(save_path + 'array_wikitext_train.npy'),np.array(tokken_corpus_train)[:-250000])\n",
    "np.save(os.path.join(save_path + 'array_wikitext_val.npy') , np.array(tokken_corpus_train)[-250000:])\n",
    "np.save(os.path.join(save_path + 'array_wikitext_test.npy'), np.array(tokken_corpus_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(save_path + 'string_list_wiki.pkl'), 'wb') as f:\n",
    "   pickle.dump(string_list, f, pickle.HIGHEST_PROTOCOL)\n",
    "# with open(r\"F:\\data\\wikitext-103-v1\\wikitext-103\\preprocessed\\itos.pkl\", 'wb') as f:\n",
    "#    pickle.dump(itos, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDB part "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### We first load all our files in memory (trn_texts,trn_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "working_folder_path= r'F:\\data\\aclImdb1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class_path = os.path.join(working_folder_path, r'imdb_clas')\n",
    "if not os.path.exists(class_path):\n",
    "    os.makedirs(class_path)\n",
    "\n",
    "lm_path = os.path.join(working_folder_path, r'imdb_lm')\n",
    "if not os.path.exists(lm_path):\n",
    "    os.makedirs(lm_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\data\\aclImdb1\\train\\neg\n",
      "F:\\data\\aclImdb1\\train\\pos\n",
      "F:\\data\\aclImdb1\\train\\unsup\n",
      "F:\\data\\aclImdb1\\test\\neg\n",
      "F:\\data\\aclImdb1\\test\\pos\n",
      "F:\\data\\aclImdb1\\test\\unsup\n"
     ]
    }
   ],
   "source": [
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        print(os.path.join(working_folder_path, path,label))\n",
    "        for fname in Path(os.path.join(working_folder_path, path,label)).glob('*'):\n",
    "            texts.append(fname.open('r', encoding='utf-8').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts),np.array(labels)\n",
    "\n",
    "trn_texts,trn_labels = get_texts('train')\n",
    "val_texts,val_labels = get_texts('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Then we shuffle it and save it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_idx    = np.random.permutation(len(trn_texts))\n",
    "val_idx    = np.random.permutation(len(val_texts))\n",
    "\n",
    "trn_texts  = trn_texts[trn_idx]\n",
    "val_texts  = val_texts[val_idx]\n",
    "\n",
    "trn_labels = trn_labels[trn_idx]\n",
    "val_labels = val_labels[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "col_names = ['labels','text']\n",
    "df_trn    = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val    = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_trn.to_csv(os.path.join(class_path,'train.csv'),header=False, index=False)\n",
    "df_val.to_csv(os.path.join(class_path,'test.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F:\\\\data\\\\aclImdb1\\\\imdb_clas'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, ..., 2, 0, 1])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concat = np.concatenate([trn_texts,val_texts], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# concat.shape\n",
    "# del concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# trn_texts,val_texts = train_test_split( concat[:50000], test_size=0.1)\n",
    "\n",
    "# df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "# df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "# df_trn.to_csv(os.path.join(lm_path,'train.csv'), header=False, index=False)\n",
    "# df_val.to_csv(os.path.join(lm_path,'test.csv') , header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Tokenisation part: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_texts(df):\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df.iloc[:,1].astype(str)\n",
    "    texts = list(texts.apply(fixup).values)\n",
    "    dfREMI = pd.DataFrame(texts)[0].apply(nltk.word_tokenize)\n",
    "\n",
    "    return pd.concat([df, dfREMI], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(os.path.join(class_path,'train.csv'), header=None)\n",
    "df_val = pd.read_csv(os.path.join(class_path,'test.csv'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_df = get_texts(df_trn)\n",
    "val_df = get_texts(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trn_df.to_csv(os.path.join(class_path,'train_tokenized.csv'), header=False, index=False)\n",
    "val_df.to_csv(os.path.join(class_path,'val_tokenized.csv')  , header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New vocab 60k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then load our data in order to convert each word to an index. We will use each of the 3 classes in order to have a sufficient vocabulary size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_df = pd.read_csv(os.path.join(class_path,'train_tokenized.csv'), header=None)\n",
    "val_df = pd.read_csv(os.path.join(class_path,'val_tokenized.csv'),  header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = Counter(p for o in trn_df.iloc[:,2].tolist() for p in o[2:-2].split(\"\\', \\'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlist_imdb = [s for s,i in freq.most_common(60000) if i >2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itos_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringlist_imdb.insert(0, '_pad_')\n",
    "stringlist_imdb.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_unk_', '_pad_', 'the', ',', '.', 'and', 'a', 'of', 'to', 'is']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringlist_imdb[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can therefore create our string to integer dictonary (stoi_imdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_imdb = collections.defaultdict(lambda:0,  {s:i for i,s in enumerate(stringlist_imdb)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all our training sentences in on array, used for the second pretraining phase.\n",
    "\n",
    "arr_train = [stoi_imdb[p] for o in trn_df[2].tolist() for p in o[2:-2].split(\"\\', \\'\")]\n",
    "np.save(r\"F:\\data\\aclImdb1\\pretrain\\array_imdb_train.npy\", np.array(arr_train) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19331955"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train = [ [stoi_imdb[p] for p in o[2:-2].split(\"\\', \\'\")] for o in trn_df[trn_df[0]!=2][2].tolist()]\n",
    "input_test  = [ [stoi_imdb[p] for p in o[2:-2].split(\"\\', \\'\")] for o in val_df[2].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = trn_df[trn_df[0]!=2][0].values.transpose()\n",
    "y_test  = val_df[0].values.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"F:\\data\\aclImdb1\\pretrain\\input_train.npy\", np.array(input_train) )\n",
    "np.save(r\"F:\\data\\aclImdb1\\pretrain\\input_test.npy\", np.array(input_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"F:\\data\\aclImdb1\\pretrain\\y_train.npy\"    , np.array(y_train) )\n",
    "np.save(r\"F:\\data\\aclImdb1\\pretrain\\y_test.npy\"    , np.array(y_test ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"F:\\data\\aclImdb1\\pretrain\\stoi_idbm.pkl\", 'wb') as f:\n",
    "#    pickle.dump(stoi_imdb, f, pickle.HIGHEST_PROTOCOL)\n",
    "with open(r\"F:\\data\\text_classification\\preprocessed_imdb\\stringlist_imdb.pkl\", 'wb') as f:\n",
    "   pickle.dump(stringlist_imdb, f, pickle.HIGHEST_PROTOCOL) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_model            = r'F:\\data\\text_classification\\model_sav\\model_wiki103_10-3.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_weight_array  = np.array(torch.load(PATH_model)['0.encoder.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector           = encoder_weight_array.mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"F:\\data\\text_classification\\preprocessed_wiki\\string_list_wiki.pkl\", 'rb') as f:\n",
    "    string_list_wiki = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight = np.zeros((len(itos_imdb),400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 400)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 30002)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stringlist_imdb), len(string_list_wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_wikitext = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(string_list_wiki)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stoi_wikitext  = collections.defaultdict(lambda:0 , {s:i for i,s in itos_wikitext.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index_imdb ,string_imdb in enumerate(stringlist_imdb):\n",
    "    indice                 = stoi_wikitext[string_imdb]\n",
    "    new_weight[index_imdb] = encoder_weight_array[indice] if indice > 0 else  mean_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do a last checking before we save our new matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hundred'"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_list_wiki[2500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25644088, -0.31902361, -0.0967235 , -0.38573858, -0.64922625,\n",
       "        1.0714463 ,  0.27908069,  0.12309778, -0.00300951,  0.51692551])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight[3149][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3149"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringlist_imdb.index(\"hundred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.25644088, -0.31902361, -0.0967235 , -0.38573858, -0.64922625,\n",
       "        1.0714463 ,  0.27908069,  0.12309778, -0.00300951,  0.51692551], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_weight_array[2500][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'F:\\data\\text_classification\\model_sav\\imdb_embedding_60002.npy',new_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### debuging part "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi_wikitext[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2601"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = {s:i for i,s in enumerate(itos_imdb)}\n",
    "stoi_imdb[\"table\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.17675555,  1.19893169, -1.13339305, -1.79974651,  1.11936235,\n",
       "       -0.58095008,  0.39032462, -1.65573072, -3.34352851, -0.79369217], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_weight_array[2500, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.17675555,  1.19893169, -1.13339305, -1.79974651,  1.11936235,\n",
       "       -0.58095008,  0.39032462, -1.65573072, -3.34352851, -0.79369217])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_weight[2601, 0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "index_imdb_list = []\n",
    "for index_imdb ,string_imdb in enumerate(itos_imdb):\n",
    "    indice                 = stoi_wikitext[string_imdb]\n",
    "    i = i+1 if indice > 0 else i\n",
    "    if indice > 0:\n",
    "            index_imdb_list.append(index_imdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58914"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_imdb_list[-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overlaping coef: 0.7398333333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"overlaping coef: {i/30000}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
